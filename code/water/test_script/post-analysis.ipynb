{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b029a0bc-2553-4a48-a34e-ecdef1e31bf9",
   "metadata": {},
   "source": [
    "### Evaluation of GAMD-large trained on RBPE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1281963-9aee-4653-b60f-0736026ea3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6518 training samples\n",
      "Using 723 testing samples\n",
      "(7241,)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=5, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=768, encoding_size=512, hidden_dim=512, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=5, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=768, encoding_size=512, hidden_dim=512, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from nn_module import WaterMDDynamicBoxNet\n",
    "from train_utils import WaterDataRealLarge\n",
    "from train_network_real_large import ParticleNetLightning\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataRealLarge(dataset_path='./md_dataset/RPBE-data-processed.npz', mode='test')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                              'box_size': [batch['box_size'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_reallarge_large/checkpoint_950.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_reallarge_large/scaler_950.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=512,\n",
    "                       hidden_dim=512,\n",
    "                       edge_embedding_dim=768,\n",
    "                      drop_edge=False,\n",
    "                       conv_layer=5,\n",
    "                      cutoff=9.5,\n",
    "                      rotate_aug=False,\n",
    "                       update_edge=False,\n",
    "                       use_part=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a325a2-8bdc-446a-b9c1-4f8cb8b94794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n"
     ]
    }
   ],
   "source": [
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos, box_size = batch['feat'].float().cuda(), batch['pos'], batch['box_size']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0], box_size[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(27/0.52917)  # hatree / bohr to ev/A\n",
    "        gt = gt.view(-1, 3)*(27/0.52917)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3288e5e7-c7bf-4545-904f-0ea54359d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos value: 0.9928294846985093\n",
      "MAE 0.019174728339468112\n",
      "std of MAE per sample: 0.014027951839411648\n",
      "RMSE: 0.028895289064118902\n",
      "std of RMSE per sample: 0.02047078281397487\n",
      "Ralative MAE: 0.011596697536030594\n",
      "Ralative std: 0.00848397493052428\n"
     ]
    }
   ],
   "source": [
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Ralative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Ralative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d39ea-fb6b-46ab-bdd4-025c6c7b7ac5",
   "metadata": {},
   "source": [
    "### Evaluation of GAMD-small trained on RBPE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fce909-dbb8-497b-adbc-1ca128f5ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6518 training samples\n",
      "Using 723 testing samples\n",
      "(7241,)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=4, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=128, encoding_size=128, hidden_dim=128, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=4, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=128, encoding_size=128, hidden_dim=128, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "\n",
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "cos value: 0.9795223481269464\n",
      "MAE 0.033374673326953125\n",
      "std of MAE per sample: 0.02098847054314041\n",
      "RMSE: 0.04776421624519811\n",
      "std of RMSE per sample: 0.029565195651719958\n",
      "Relative MAE: 0.020184692324420137\n",
      "Relative std: 0.012693631968265928\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from nn_module import WaterMDDynamicBoxNet\n",
    "from train_utils import WaterDataRealLarge\n",
    "from train_network_real_large import ParticleNetLightning\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataRealLarge(dataset_path='./md_dataset/RPBE-data-processed.npz', mode='test')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                              'box_size': [batch['box_size'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_reallarge_small/checkpoint_950.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_reallarge_small/scaler_950.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=128,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=128,\n",
    "                      drop_edge=False,\n",
    "                       conv_layer=4,\n",
    "                      cutoff=9.5,\n",
    "                      rotate_aug=False,\n",
    "                       update_edge=False,\n",
    "                       use_part=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')\n",
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos, box_size = batch['feat'].float().cuda(), batch['pos'], batch['box_size']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0], box_size[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(27/0.52917)  # hatree / bohr to ev/A\n",
    "        gt = gt.view(-1, 3)*(27/0.52917)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1\n",
    "        \n",
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Relative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Relative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90fe23-4dba-483b-b508-87e14cf3485d",
   "metadata": {},
   "source": [
    "### Evaluation of GAMD using only part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa5a56d2-3ca9-4385-9370-4ac0fb77b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6518 training samples\n",
      "Using 723 testing samples\n",
      "(7241,)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=5, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=256, encoding_size=256, hidden_dim=128, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=5, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=256, encoding_size=256, hidden_dim=128, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "\n",
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "cos value: 0.9621473527852384\n",
      "MAE 0.0761859785255583\n",
      "std of MAE per sample: 0.03553132046224863\n",
      "RMSE: 0.10641007862431771\n",
      "std of RMSE per sample: 0.04969007950127709\n",
      "Relative MAE: 0.04607657192351802\n",
      "Relative std: 0.021489012473169773\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from nn_module import WaterMDDynamicBoxNet\n",
    "from train_utils import WaterDataRealLarge\n",
    "from train_network_real_large import ParticleNetLightning\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataRealLarge(dataset_path='./md_dataset/RPBE-data-processed.npz', mode='test')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                              'box_size': [batch['box_size'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_reallarge_part/checkpoint_950.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_reallarge_part/scaler_950.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=256,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=256,\n",
    "                      drop_edge=False,\n",
    "                       conv_layer=5,\n",
    "                      cutoff=9.5,\n",
    "                      rotate_aug=False,\n",
    "                       update_edge=False,\n",
    "                       use_part=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')\n",
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos, box_size = batch['feat'].float().cuda(), batch['pos'], batch['box_size']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0], box_size[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(27/0.52917)  # hatree / bohr to ev/A\n",
    "        gt = gt.view(-1, 3)*(27/0.52917)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1\n",
    "        \n",
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Relative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Relative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603ed65-4ea9-4775-96d1-27f2f7405663",
   "metadata": {},
   "source": [
    "### GAMD on TIP3P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b0d06-03d5-4f4a-8bcc-a981e6096cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from train_utils import WaterDataNew\n",
    "from train_network_tip3p import ParticleNetLightning, NUM_OF_ATOMS\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataNew(dataset_path=os.path.join('./md_dataset', 'water_data_tip3p'),\n",
    "                               sample_num=1000,\n",
    "                               case_prefix='data_',\n",
    "                               seed_num=10,\n",
    "                               m_num=NUM_OF_ATOMS//3,\n",
    "                               mode='test',\n",
    "                               data_type='tip3p')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_tip3pnew_long/checkpoint_28.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_tip3pnew_long/scaler_28.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=128,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=128,\n",
    "                      drop_edge=False,\n",
    "                      rotate_aug=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f690c6c-fb85-496c-9caa-6b0a97eabf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "Finished 800\n"
     ]
    }
   ],
   "source": [
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos = batch['feat'].float().cuda(), batch['pos']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(0.0010364)  # KJ/mol to ev/A\n",
    "        gt = gt.view(-1, 3)*(0.0010364)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88829ff-5313-4763-8626-2bdbd27d8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos value: 0.9996882728811234\n",
      "MAE 0.011263003440500439\n",
      "std of MAE per sample: 0.0008416153970639325\n",
      "RMSE: 0.015159353023402752\n",
      "std of RMSE per sample: 0.0011593059574419755\n",
      "Ralative MAE: 0.011608358915583617\n",
      "Ralative std: 0.000867421700580201\n"
     ]
    }
   ],
   "source": [
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Ralative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Ralative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac04def-b4bd-42e4-b9a3-f657595f7906",
   "metadata": {},
   "source": [
    "### GAMD on TIP4P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7133df-0587-4359-8c9e-a9a8de4a63d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including atom type: 2\n",
      "Using following set of hyper-parameters\n",
      "{'in_feats': 1, 'encoding_size': 128, 'out_feats': 3, 'bond': array([[  0,   1],\n",
      "       [  0,   2],\n",
      "       [  3,   4],\n",
      "       ...,\n",
      "       [747, 749],\n",
      "       [750, 751],\n",
      "       [750, 752]]), 'hidden_dim': 128, 'edge_embedding_dim': 128, 'conv_layer': 4, 'drop_edge': False, 'use_layer_norm': True, 'box_size': 20.0}\n",
      "Using following set of hyper-parameters\n",
      "{'in_feats': 1, 'encoding_size': 128, 'out_feats': 3, 'bond': array([[  0,   1],\n",
      "       [  0,   2],\n",
      "       [  3,   4],\n",
      "       ...,\n",
      "       [747, 749],\n",
      "       [750, 751],\n",
      "       [750, 752]]), 'hidden_dim': 128, 'edge_embedding_dim': 128, 'conv_layer': 4, 'drop_edge': False, 'use_layer_norm': True, 'box_size': 20.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from train_utils import WaterDataNew\n",
    "from train_network_tip4p import ParticleNetLightning, NUM_OF_ATOMS\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataNew(dataset_path=os.path.join('./md_dataset', 'water_data_tip4p'),\n",
    "                               sample_num=1000,\n",
    "                               case_prefix='data_',\n",
    "                               seed_num=10,\n",
    "                               m_num=NUM_OF_ATOMS//3,\n",
    "                               mode='test',\n",
    "                               data_type='tip4p')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_tip4pnew3_marked/checkpoint_19.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_tip4pnew3_marked/scaler_19.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=128,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=128,\n",
    "                      drop_edge=False,\n",
    "                      rotate_aug=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db50d9ba-4b7e-48b8-a3fb-08f85b798e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "Finished 800\n"
     ]
    }
   ],
   "source": [
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "o_ratios = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos = batch['feat'].float().cuda(), batch['pos']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(0.0010364)  # KJ/mol to ev/A\n",
    "        gt = gt.view(-1, 3)*(0.0010364)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294883fa-2055-4771-a036-eb5cee7633a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Ralative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Ralative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c3cc4-efa7-4826-b8b5-2669513fff5b",
   "metadata": {},
   "source": [
    "### GAMD-med on RPBE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fa52dc-9140-4187-8acd-f8622805d96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6518 training samples\n",
      "Using 723 testing samples\n",
      "(7241,)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=5, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=256, encoding_size=256, hidden_dim=128, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "Using following set of hyper-parameters\n",
      "namespace(conv_layer=5, cutoff=9.5, data_dir='', drop_edge=False, edge_embedding_dim=256, encoding_size=256, hidden_dim=128, loss='mae', rotate_aug=False, update_edge=False, use_layer_norm=True, use_part=False)\n",
      "\n",
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "cos value: 0.9858087938310441\n",
      "MAE 0.02428514585951099\n",
      "std of MAE per sample: 0.016796812913669183\n",
      "RMSE: 0.03538629214569198\n",
      "std of RMSE per sample: 0.02309355171008023\n",
      "Relative MAE: 0.014687430568257363\n",
      "Relative std: 0.01015855638111833\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from nn_module import WaterMDDynamicBoxNet\n",
    "from train_utils import WaterDataRealLarge\n",
    "from train_network_real_large import ParticleNetLightning\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataRealLarge(dataset_path='./md_dataset/RPBE-data-processed.npz', mode='test')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                              'box_size': [batch['box_size'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_reallarge_reg/checkpoint_798.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_reallarge_reg/scaler_798.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=256,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=256,\n",
    "                      drop_edge=False,\n",
    "                       conv_layer=5,\n",
    "                      cutoff=9.5,\n",
    "                      rotate_aug=False,\n",
    "                       update_edge=False,\n",
    "                       use_part=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')\n",
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos, box_size = batch['feat'].float().cuda(), batch['pos'], batch['box_size']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0], box_size[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(27/0.52917)  # hatree / bohr to ev/A\n",
    "        gt = gt.view(-1, 3)*(27/0.52917)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1\n",
    "        \n",
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Relative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Relative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd31f97-f971-45d0-bcd0-5043b4581ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including atom type: 2\n",
      "Using following set of hyper-parameters\n",
      "{'in_feats': 1, 'encoding_size': 128, 'out_feats': 3, 'hidden_dim': 128, 'edge_embedding_dim': 128, 'conv_layer': 4, 'drop_edge': False, 'use_layer_norm': True, 'box_size': 20.0}\n",
      "Using following set of hyper-parameters\n",
      "{'in_feats': 1, 'encoding_size': 128, 'out_feats': 3, 'hidden_dim': 128, 'edge_embedding_dim': 128, 'conv_layer': 4, 'drop_edge': False, 'use_layer_norm': True, 'box_size': 20.0}\n",
      "\n",
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "Finished 800\n",
      "cos value: 0.9996864148707305\n",
      "MAE 0.01103301183405695\n",
      "std of MAE per sample: 0.0008425929414812384\n",
      "RMSE: 0.014894169469857357\n",
      "std of RMSE per sample: 0.0011784660567412755\n",
      "Relative MAE: 0.011371315117339954\n",
      "Relative std: 0.0008684292192684407\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from nn_module import WaterMDDynamicBoxNet\n",
    "from train_utils import WaterDataNew\n",
    "from train_network_tip3p import ParticleNetLightning, NUM_OF_ATOMS\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataNew(dataset_path=os.path.join('./md_dataset', 'water_data_tip3p'),\n",
    "                               sample_num=1000,\n",
    "                               case_prefix='data_',\n",
    "                               seed_num=10,\n",
    "                               m_num=NUM_OF_ATOMS//3,\n",
    "                               mode='test',\n",
    "                               data_type='tip3p')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_no_expand/checkpoint_20.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_no_expand/scaler_20.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=128,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=128,\n",
    "                      drop_edge=False,\n",
    "                      rotate_aug=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')\n",
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos = batch['feat'].float().cuda(), batch['pos']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(0.0010364)  # KJ/mol to ev/A\n",
    "        gt = gt.view(-1, 3)*(0.0010364)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1\n",
    "        \n",
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Relative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Relative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c157ce8c-7742-4f0a-b3fa-2d389217e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including atom type: 2\n",
      "Using following set of hyper-parameters\n",
      "{'in_feats': 1, 'encoding_size': 128, 'out_feats': 3, 'hidden_dim': 128, 'edge_embedding_dim': 128, 'conv_layer': 4, 'drop_edge': False, 'use_layer_norm': True, 'box_size': 20.0}\n",
      "Using following set of hyper-parameters\n",
      "{'in_feats': 1, 'encoding_size': 128, 'out_feats': 3, 'hidden_dim': 128, 'edge_embedding_dim': 128, 'conv_layer': 4, 'drop_edge': False, 'use_layer_norm': True, 'box_size': 20.0}\n",
      "\n",
      "Finished 0\n",
      "Finished 200\n",
      "Finished 400\n",
      "Finished 600\n",
      "Finished 800\n",
      "cos value: 0.999333254594678\n",
      "MAE 0.018202764408322854\n",
      "std of MAE per sample: 0.0012427714472495637\n",
      "RMSE: 0.025138951862883827\n",
      "std of RMSE per sample: 0.004354936167142915\n",
      "Relative MAE: 0.01688869452463752\n",
      "Relative std: 0.0011530549352681203\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from train_utils import WaterDataNew\n",
    "from train_network_tip4p import ParticleNetLightning, NUM_OF_ATOMS\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataNew(dataset_path=os.path.join('./md_dataset', 'water_data_new'),\n",
    "                               sample_num=1000,\n",
    "                               case_prefix='data_',\n",
    "                               seed_num=10,\n",
    "                               m_num=NUM_OF_ATOMS//3,\n",
    "                               mode='test',\n",
    "                               data_type='tip4p')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_tip4p_nobond/checkpoint_10.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_tip4p_nobond/scaler_10.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=128,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=128,\n",
    "                      drop_edge=False,\n",
    "                      rotate_aug=False,\n",
    "                      data_dir='',\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')\n",
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos = batch['feat'].float().cuda(), batch['pos']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(0.0010364)  # KJ/mol to ev/A\n",
    "        gt = gt.view(-1, 3)*(0.0010364)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1\n",
    "        \n",
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Relative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Relative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a9d72-cfd8-4a12-ade1-67432465135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('../',os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "from nn_module import WaterMDDynamicBoxNet\n",
    "from train_utils import WaterDataRealLarge\n",
    "from train_network_real_large import ParticleNetLightning\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "dataset = WaterDataRealLarge(dataset_path='./md_dataset/RPBE-data-processed.npz', mode='test')\n",
    "dataloader = DataLoader(dataset, num_workers=2, batch_size=1, shuffle=False,\n",
    "                          collate_fn=\n",
    "                          lambda batches: {\n",
    "                              'feat': torch.cat([torch.from_numpy(batch['feat']).float() for batch in batches], dim=0),\n",
    "                              'pos': [batch['pos'] for batch in batches],\n",
    "                              'forces': [batch['forces'] for batch in batches],\n",
    "                              'box_size': [batch['box_size'] for batch in batches],\n",
    "                          })\n",
    "\n",
    "PATH = './model_ckpt_reallarge_noexpand/checkpoint_798.ckpt'\n",
    "SCALER_CKPT = './model_ckpt_reallarge_noexpand/scaler_798.npz'\n",
    "args = SimpleNamespace(use_layer_norm=True,\n",
    "                       encoding_size=256,\n",
    "                       hidden_dim=128,\n",
    "                       edge_embedding_dim=256,\n",
    "                      drop_edge=False,\n",
    "                       conv_layer=5,\n",
    "                      cutoff=9.5,\n",
    "                      rotate_aug=False,\n",
    "                       update_edge=False,\n",
    "                       use_part=False,\n",
    "                      data_dir='',\n",
    "                      expand_edge=False,\n",
    "                      loss='mae')\n",
    "model = ParticleNetLightning(args).load_from_checkpoint(PATH, args=args)\n",
    "model.load_training_stats(SCALER_CKPT)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "print('')\n",
    "cos_vals = []\n",
    "force = []\n",
    "force_gt = []\n",
    "mae = []\n",
    "se = []\n",
    "num = []\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "\n",
    "        feat, pos, box_size = batch['feat'].float().cuda(), batch['pos'], batch['box_size']\n",
    "        gt = torch.from_numpy(batch['forces'][0]).float().cuda()\n",
    "\n",
    "        feat = feat.cuda()\n",
    "        force_np = model.predict_forces(feat, pos[0], box_size[0])\n",
    "        force_tsr = torch.from_numpy(force_np).cuda()\n",
    "        cos_val = torch.sum(force_tsr * gt, dim=1) / (force_tsr.norm(dim=1)*gt.norm(dim=1))\n",
    "        force_tsr = force_tsr.view(-1, 3)*(27/0.52917)  # hatree / bohr to ev/A\n",
    "        gt = gt.view(-1, 3)*(27/0.52917)\n",
    "        force += [force_tsr.cpu().numpy()]\n",
    "        force_gt += [gt.cpu().numpy()]\n",
    "        mae += [torch.sum(torch.mean(torch.abs(force_tsr - gt), dim=1)).cpu().numpy()]\n",
    "        se += [torch.sum(torch.mean((force_tsr-gt)**2, dim=1)).cpu().numpy()]\n",
    "        num += [pos[0].shape[0]]\n",
    "        cos_vals += [cos_val]\n",
    "        if count%200 == 0:\n",
    "            print(f\"Finished {i_batch}\")\n",
    "        count += 1\n",
    "        \n",
    "print(f'cos value: {torch.mean(torch.cat(cos_vals))}')\n",
    "print(f'MAE {np.sum(mae) / np.sum(num)}')\n",
    "print(f'std of MAE per sample: {np.std([mae[i]/num[i] for i in range(len(num))])}')\n",
    "print(f'RMSE: {np.sqrt(np.sum(se)/ np.sum(num))}')\n",
    "print(f'std of RMSE per sample: {np.std([np.sqrt(se[i]/num[i]) for i in range(len(num))])}')\n",
    "print(f'Relative MAE: {(np.sum(mae) / np.sum(num))/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')\n",
    "print(f'Relative std: {np.std([mae[i]/num[i] for i in range(len(num))])/ np.mean(np.linalg.norm(np.concatenate(force_gt), axis=-1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a14cda-1cf1-4926-a42d-b863cdb7e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
